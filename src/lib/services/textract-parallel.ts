/**
 * Parallel PDF Extraction with AWS Textract
 *
 * Optimized for POP Trading Company workflow:
 * - 60 invoices per upload (Drop 1, Drop 2, Deposits)
 * - Sequential: 15 minutes ‚Üí Parallel: 2-3 minutes
 *
 * Key improvements:
 * 1. True parallel job polling (not just parallel starts)
 * 2. Batch processing with AWS Textract limits
 * 3. Real-time progress updates
 * 4. Robust error handling per invoice
 */

import { S3Client, PutObjectCommand, DeleteObjectCommand } from '@aws-sdk/client-s3'
import {
  TextractClient,
  StartDocumentAnalysisCommand,
  GetDocumentAnalysisCommand,
} from '@aws-sdk/client-textract'

// ============================================================================
// Configuration
// ============================================================================

const AWS_REGION = process.env.AWS_REGION || 'us-east-1'
const S3_BUCKET = process.env.AWS_S3_BUCKET || 'reminder-mvp-textract-pdfs'

// AWS Textract concurrent job limits (account-dependent)
// Free tier: typically 10-20 concurrent jobs
// Standard: 50-100 concurrent jobs
// Adjusted based on rate limiting errors
const MAX_CONCURRENT_JOBS = 20

// Polling configuration
const POLL_INTERVAL_MS = 3000 // Check every 3 seconds
const MAX_POLL_ATTEMPTS = 60 // Maximum 3 minutes of polling per job

const s3Client = new S3Client({ region: AWS_REGION })
const textractClient = new TextractClient({ region: AWS_REGION })

// ============================================================================
// Types
// ============================================================================

export interface PDFInput {
  fileName: string
  buffer: Buffer
}

export interface ExtractedInvoiceData {
  invoiceNumber?: string
  customerName?: string
  amount?: number
  totalAmount?: number
  currency?: string
  invoiceDate?: string
  dueDate?: string
  confidence: number
  rawText: string
}

export interface ExtractionResult {
  fileName: string
  success: boolean
  data?: ExtractedInvoiceData
  error?: string
  processingTimeMs: number
}

export interface ProgressUpdate {
  completed: number
  total: number
  currentBatch: number
  totalBatches: number
  successCount: number
  failCount: number
  results: ExtractionResult[]
}

// ============================================================================
// Helper Functions
// ============================================================================

function chunk<T>(array: T[], size: number): T[][] {
  const chunks: T[][] = []
  for (let i = 0; i < array.length; i += size) {
    chunks.push(array.slice(i, i + size))
  }
  return chunks
}

const sleep = (ms: number) => new Promise((resolve) => setTimeout(resolve, ms))

// ============================================================================
// S3 Operations
// ============================================================================

async function uploadToS3(
  buffer: Buffer,
  fileName: string
): Promise<{ bucket: string; key: string }> {
  const key = `invoices/${Date.now()}-${fileName}`

  await s3Client.send(
    new PutObjectCommand({
      Bucket: S3_BUCKET,
      Key: key,
      Body: buffer,
      ContentType: 'application/pdf',
    })
  )

  return { bucket: S3_BUCKET, key }
}

async function deleteFromS3(bucket: string, key: string): Promise<void> {
  try {
    await s3Client.send(new DeleteObjectCommand({ Bucket: bucket, Key: key }))
  } catch (error) {
    console.error(`S3 cleanup failed for ${key}:`, error)
    // Don't throw - cleanup failures shouldn't break the flow
  }
}

// ============================================================================
// Textract Operations
// ============================================================================

async function startTextractJob(
  bucket: string,
  key: string
): Promise<string> {
  const command = new StartDocumentAnalysisCommand({
    DocumentLocation: {
      S3Object: { Bucket: bucket, Name: key },
    },
    FeatureTypes: ['TABLES', 'FORMS'],
  })

  const response = await textractClient.send(command)

  if (!response.JobId) {
    throw new Error('Textract failed to return JobId')
  }

  return response.JobId
}

async function pollTextractJob(jobId: string): Promise<string> {
  let attempts = 0

  while (attempts < MAX_POLL_ATTEMPTS) {
    const command = new GetDocumentAnalysisCommand({ JobId: jobId })
    const response = await textractClient.send(command)

    if (response.JobStatus === 'SUCCEEDED') {
      // Extract all text from LINE blocks
      const text =
        response.Blocks?.filter((block) => block.BlockType === 'LINE')
          .map((block) => block.Text)
          .join('\n') || ''

      return text
    }

    if (response.JobStatus === 'FAILED') {
      throw new Error(`Textract job failed: ${response.StatusMessage || 'Unknown error'}`)
    }

    // Still in progress - wait and retry
    attempts++
    await sleep(POLL_INTERVAL_MS)
  }

  throw new Error(`Textract job timed out after ${MAX_POLL_ATTEMPTS} attempts (${(MAX_POLL_ATTEMPTS * POLL_INTERVAL_MS) / 1000}s)`)
}

// ============================================================================
// Invoice Data Parsing
// ============================================================================

function parseInvoiceData(text: string): ExtractedInvoiceData {
  // Basic pattern matching - this is what your existing TextractAsyncParser does
  const patterns = {
    invoiceNumber: /(?:invoice\s+number|invoice\s+#|inv\s*#?)[:\s]+([A-Z0-9-]+)/i,
    amount: /(?:total|amount|grand\s+total)[:\s]+(?:‚Ç¨|EUR|AED)?\s*([\d,]+\.?\d*)/i,
    customerName: /(?:bill\s+to|customer|debtor)[:\s]+([^\n]+)/i,
    invoiceDate: /(?:invoice\s+date|date)[:\s]+([\d]{1,2}[-/][\d]{1,2}[-/][\d]{2,4})/i,
    dueDate: /(?:due\s+date|payment\s+due)[:\s]+([\d]{1,2}[-/][\d]{1,2}[-/][\d]{2,4})/i,
  }

  const invoiceNumber = text.match(patterns.invoiceNumber)?.[1]
  const amountMatch = text.match(patterns.amount)
  const amount = amountMatch ? parseFloat(amountMatch[1].replace(/,/g, '')) : undefined
  const customerName = text.match(patterns.customerName)?.[1]?.trim()
  const invoiceDate = text.match(patterns.invoiceDate)?.[1]
  const dueDate = text.match(patterns.dueDate)?.[1]

  // Calculate confidence based on required fields found
  const requiredFields = [invoiceNumber, amount, customerName]
  const foundFields = requiredFields.filter((f) => f !== undefined).length
  const confidence = (foundFields / requiredFields.length) * 100

  return {
    invoiceNumber,
    customerName,
    amount,
    totalAmount: amount,
    currency: 'EUR', // Default - POP Trading uses EUR
    invoiceDate,
    dueDate,
    confidence,
    rawText: text,
  }
}

// ============================================================================
// Main Extraction Function - TRUE PARALLEL PROCESSING
// ============================================================================

/**
 * Extract data from multiple PDFs with true parallel processing
 *
 * This implementation:
 * 1. Uploads all PDFs to S3 in parallel
 * 2. Starts all Textract jobs in parallel
 * 3. Polls all jobs in parallel (this is the key difference!)
 *
 * For 60 PDFs: ~2-3 minutes total (vs 15 minutes sequential)
 */
export async function extractPDFsInParallel(
  pdfs: PDFInput[],
  onProgress?: (progress: ProgressUpdate) => void
): Promise<ExtractionResult[]> {
  const totalPDFs = pdfs.length
  const startTime = Date.now()

  console.log(`\nüöÄ Starting parallel extraction of ${totalPDFs} PDFs`)
  console.log(`‚öôÔ∏è  Max concurrent jobs: ${MAX_CONCURRENT_JOBS}\n`)

  // Split into batches based on AWS Textract concurrent job limit
  const batches = chunk(pdfs, MAX_CONCURRENT_JOBS)
  const allResults: ExtractionResult[] = []

  for (let batchIndex = 0; batchIndex < batches.length; batchIndex++) {
    const batch = batches[batchIndex]
    const batchNumber = batchIndex + 1

    console.log(`üì¶ Processing batch ${batchNumber}/${batches.length} (${batch.length} PDFs)`)

    try {
      // STEP 1: Upload all PDFs in this batch to S3 in parallel
      console.log(`   ‚¨ÜÔ∏è  Uploading ${batch.length} PDFs to S3...`)
      const uploadStartTime = Date.now()

      const uploadPromises = batch.map(async (pdf) => {
        try {
          const { bucket, key } = await uploadToS3(pdf.buffer, pdf.fileName)
          return { pdf, bucket, key, uploadError: null }
        } catch (error) {
          return {
            pdf,
            bucket: '',
            key: '',
            uploadError: error instanceof Error ? error.message : 'Upload failed',
          }
        }
      })

      const uploads = await Promise.all(uploadPromises)
      const uploadTime = Date.now() - uploadStartTime
      console.log(`   ‚úì Uploads complete (${(uploadTime / 1000).toFixed(1)}s)`)

      // STEP 2: Start all Textract jobs in parallel
      console.log(`   üîÑ Starting ${uploads.length} Textract jobs...`)
      const startJobsTime = Date.now()

      const jobPromises = uploads.map(async (upload) => {
        if (upload.uploadError) {
          return { ...upload, jobId: null, startError: upload.uploadError }
        }

        try {
          const jobId = await startTextractJob(upload.bucket, upload.key)
          return { ...upload, jobId, startError: null }
        } catch (error) {
          return {
            ...upload,
            jobId: null,
            startError: error instanceof Error ? error.message : 'Failed to start job',
          }
        }
      })

      const jobs = await Promise.all(jobPromises)
      const startJobsTimeElapsed = Date.now() - startJobsTime
      console.log(`   ‚úì Jobs started (${(startJobsTimeElapsed / 1000).toFixed(1)}s)`)

      // STEP 3: Poll all jobs in parallel (THIS IS THE KEY!)
      console.log(`   ‚è≥ Polling ${jobs.length} jobs for completion...`)
      const pollStartTime = Date.now()

      const pollPromises = jobs.map(async (job) => {
        const startTime = Date.now()

        // Handle upload or start errors
        if (job.uploadError || job.startError) {
          return {
            fileName: job.pdf.fileName,
            success: false,
            error: job.uploadError || job.startError,
            processingTimeMs: Date.now() - startTime,
          }
        }

        try {
          // Poll for completion
          const extractedText = await pollTextractJob(job.jobId!)

          // Cleanup S3
          await deleteFromS3(job.bucket, job.key)

          // Parse invoice data
          const data = parseInvoiceData(extractedText)

          return {
            fileName: job.pdf.fileName,
            success: true,
            data,
            processingTimeMs: Date.now() - startTime,
          }
        } catch (error) {
          // Cleanup S3 even on error
          await deleteFromS3(job.bucket, job.key)

          return {
            fileName: job.pdf.fileName,
            success: false,
            error: error instanceof Error ? error.message : 'Extraction failed',
            processingTimeMs: Date.now() - startTime,
          }
        }
      })

      const batchResults = await Promise.all(pollPromises)
      const pollTime = Date.now() - pollStartTime
      console.log(`   ‚úì Polling complete (${(pollTime / 1000).toFixed(1)}s)`)

      allResults.push(...batchResults)

      // Calculate progress
      const successCount = allResults.filter((r) => r.success).length
      const failCount = allResults.filter((r) => !r.success).length

      console.log(
        `   ‚úÖ Batch ${batchNumber} complete: ${successCount} success, ${failCount} failed\n`
      )

      // Call progress callback
      if (onProgress) {
        onProgress({
          completed: allResults.length,
          total: totalPDFs,
          currentBatch: batchNumber,
          totalBatches: batches.length,
          successCount,
          failCount,
          results: allResults,
        })
      }
    } catch (error) {
      console.error(`‚ùå Batch ${batchNumber} failed:`, error)
      // Continue to next batch even if this one fails
    }
  }

  const totalTime = Date.now() - startTime
  const avgTimePerPDF = totalTime / totalPDFs
  const successCount = allResults.filter((r) => r.success).length
  const failCount = allResults.filter((r) => !r.success).length

  console.log(`\n‚úÖ All batches processed!`)
  console.log(`   Total time: ${(totalTime / 1000).toFixed(1)}s`)
  console.log(`   Avg per PDF: ${(avgTimePerPDF / 1000).toFixed(1)}s`)
  console.log(`   Success: ${successCount}`)
  console.log(`   Failed: ${failCount}\n`)

  return allResults
}

// ============================================================================
// Convenience Wrapper with Simple API
// ============================================================================

/**
 * Extract a single PDF (useful for testing)
 */
export async function extractSinglePDF(
  fileName: string,
  buffer: Buffer
): Promise<ExtractionResult> {
  const results = await extractPDFsInParallel([{ fileName, buffer }])
  return results[0]
}
